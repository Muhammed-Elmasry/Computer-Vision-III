{"cells":[{"cell_type":"markdown","metadata":{"id":"PdTfwMgubn1E"},"source":["# Exercise 03\n","## Re-ID with Graph Neural Networks\n","\n","In this exercise, we will first create an extension of the IoU- and ReID-based tracker we created in the previous exercise that will make it more robust to occlusions by allowing it to recover from missed detections.\n","\n","We will then implement a Message Passing Network that we will use to learn features that combine position and appearance information. On these edge features, we then base our prediction on associations between past tracks and new detections.\n","\n","<!-- TODO: adapt tasks -->\n","Your tasks are the following:\n","- Adapt the track management scheme of our Tracker to allow it to recover from missed detections.\n","- Implement the Update Operation for the Message Passing Network to operate on bipartite graphs\n","- Implement the pairwise motion feature computation to obtain initial features for the edges of our Message Passing Network\n","- Train the Message Passing Network and improve your tracker's IDF1 score\n","- Use the Message Passing Network instead of the distance matrix in the Tracker"]},{"cell_type":"markdown","metadata":{"id":"OfBMM8p2bn1H"},"source":["## Imports\n","\n","This will setup your whole environment such that you can work with the rest of the notebook.\n","\n","### General Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"83JM5FmXbn1H","executionInfo":{"status":"ok","timestamp":1702743156226,"user_tz":-60,"elapsed":5568,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}}},"outputs":[],"source":["from pathlib import Path\n","\n","import torch\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"2FVDjCvSbn1I"},"source":["## Set up directory paths and (optionally) mount in Google Colab\n","If you work with google colab set the `USING_COLAB` variable to `True` and following cell to mount your gdrive."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ESehhEkbn1I","executionInfo":{"status":"ok","timestamp":1702743188848,"user_tz":-60,"elapsed":32629,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"7bf5426c-28b5-40fb-cb01-646fa05dac0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","['exercise_03', 'exercise_03.zip', 'exercise_code', 'models', 'reid_gnn.ipynb', 'reid_gnn.zip']\n"]}],"source":["USING_COLAB = True\n","USE_CPU = False\n","# Use the following lines if you want to use Google Colab\n","# We presume you created a folder \"cv3dst\" within your main drive folder, and put the exercise there.\n","# NOTE: terminate all other colab sessions that use GPU!\n","# NOTE 2: Make sure the correct exercise folder (e.g exercise_03) is given.\n","\n","if USING_COLAB:\n","    from google.colab import drive\n","    import os\n","\n","    gdrive_path='/content/gdrive/MyDrive/masters/CVIII/task3'\n","\n","    # This will mount your google drive under 'MyDrive'\n","    drive.mount('/content/gdrive', force_remount=True)\n","    # In order to access the files in this notebook we have to navigate to the correct folder\n","    os.chdir(gdrive_path)\n","    # Check manually if all files are present\n","    print(sorted(os.listdir()))\n","    root_dir = Path(gdrive_path).parent\n","else:\n","    root_dir = Path('./cv3dst/')\n","# NOTE: Also adjust the root_dir in test/hungarian_tracking.py\n","\n","dataset_dir = root_dir.joinpath(\"datasets\")\n","output_dir = root_dir.joinpath('exercise_03', 'models')\n","output_dir.mkdir(parents=True, exist_ok=True)\n","\n","device = torch.device('cuda') if torch.cuda.is_available() and not USE_CPU else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"IAW4Q0BCbn1J"},"source":["### Exercise Specific Imports"]},{"cell_type":"code","source":["!pip install motmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFnrHkx6cUkm","executionInfo":{"status":"ok","timestamp":1702743196636,"user_tz":-60,"elapsed":7794,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"7b648fa4-d79b-4e8c-ff64-9b8491a42d1c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting motmetrics\n","  Downloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from motmetrics) (1.23.5)\n","Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from motmetrics) (1.5.3)\n","Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from motmetrics) (1.11.4)\n","Collecting xmltodict>=0.12.0 (from motmetrics)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.1->motmetrics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.1->motmetrics) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23.1->motmetrics) (1.16.0)\n","Installing collected packages: xmltodict, motmetrics\n","Successfully installed motmetrics-1.4.0 xmltodict-0.13.0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"q-VXWIoBbn1J","executionInfo":{"status":"ok","timestamp":1702743219980,"user_tz":-60,"elapsed":23352,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}}},"outputs":[],"source":["from exercise_code import (\n","    MOT16Sequences,\n","    LongTrackTrainingDataset,\n",")\n","\n","from exercise_code import (\n","    Hungarian_TrackerIoUReID,\n","    Longterm_Hungarian_TrackerIoUReID,\n","    MPN_Tracker,\n","    AssignmentSimilarityNet,\n","    train_assign_net_one_epoch,\n","    evaluate_assign_net,\n",")\n","\n","from exercise_code.test import (\n","    test_inactive_tracks,\n","    test_neural_message_passing_1,\n","    test_neural_message_passing_2,\n","    test_mpn_tracking_forward_pass,\n","    test_longterm_hungarian_tracking_ioureid,\n","    test_mpn_tracking,\n","    val_mpn_tracking,\n","    run_tracker\n",")\n","\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"IhK3ebdWbn1K"},"source":["# Exercise Part I - Long-Term ReID Tracker\n","The tracker `Hungarian_TrackerIoUReID` in `exercise_code/model/hungarian_tracker.py` has an obvious limitation: whenever we can not match a track with the detections of a given frame, the track will be killed (line 54). Therefore, if our detector misses an object in a single frame (due to, e.g. occlusion), we will not be able to recover that track, and we will start a new one.\n","\n","We want to allow the tracker to maintain unmatched tracks to fix this issue and refer to these tracks as inactive. During data association, we try to match the detected boxes for the current frame to the active and inactive tracks. Therefore, if a detector misses an object in a frame and the object reappears after a few frames, we try to match it to its corresponding track instead of creating a new one.\n","\n","We use the `inactive` attribute from the `track` class in `exercise_code/model/tracker.py` to adapt our tracker. This attribute is a counter and shows how many frames a track has remained unmatched. Whenever we can match the track, we will set `inactive=0`; otherwise, we increase the counter."]},{"cell_type":"markdown","metadata":{"id":"9dLLXTO-bn1K"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Inactive tracks</h3>\n","    <p> Go to <code>exercise_code/hungarian_tracker.py</code> and the <code>update_tracks</code> method. You must update the <code>inactive</code> attribute for the unmatched tracks. Also, remove those tracks where the <code>inactive</code> counter is bigger than the <code>patience</code>.</p>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"F2IIAU7Xbn1K"},"source":["<div class=\"alert alert-danger\">\n","    <h3>Test: Inactive tracks</h3>\n","    <p> Run the following cell to execute the test case for the inactive tracker.</p>\n","</div>"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgDmn7zbbn1L","executionInfo":{"status":"ok","timestamp":1702743222516,"user_tz":-60,"elapsed":2541,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"feb140f7-ab43-4221-bfca-15ea61b5a557"},"outputs":[{"output_type":"stream","name":"stdout","text":["Congratulations: No tracks have been removed before patience was reached.\n","Congratulations: No tracks have been removed before patience was reached. Counter is correct.\n","Congratulations: Tracks have been removed after patience was reached.\n","All tests of InactiveTracksTest passed. Tests passed: 3/3\n","Score: 100/100\n"]}],"source":["_ = test_inactive_tracks()"]},{"cell_type":"markdown","metadata":{"id":"IkL7k_dEbn1L"},"source":["If the previous test ran successfully you can now run the tracker on the validation sequence to evaluate its results."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gdUwHdCbn1L","executionInfo":{"status":"ok","timestamp":1702743248063,"user_tz":-60,"elapsed":25555,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"c0c98f2c-316f-4cae-a30c-e52bf1c74956"},"outputs":[{"output_type":"stream","name":"stdout","text":["Runtime for all sequences: 4.0 s.\n"]}],"source":["old_tracker = False\n","if old_tracker:\n","    tracker = Hungarian_TrackerIoUReID()\n","else:\n","    tracker = Longterm_Hungarian_TrackerIoUReID(patience=10)\n","\n","train_db = torch.load(dataset_dir.joinpath('reid_gnn', 'preprocessed_data_train_2.pth'))\n","val_sequences = MOT16Sequences('MOT16-reid', root_dir = dataset_dir.joinpath('MOT16'), vis_threshold=0.)\n","results_seq = run_tracker(val_sequences, train_db, tracker, device=device)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lNYuxjZobn1L","executionInfo":{"status":"ok","timestamp":1702743250150,"user_tz":-60,"elapsed":2102,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}}},"outputs":[],"source":["torch.save(results_seq, \"exercise_code/test/\"+tracker.name+\".pth\")"]},{"cell_type":"markdown","metadata":{"id":"hYEZDgUwbn1L"},"source":["<div class=\"alert alert-danger\">\n","    <h3>Test: Inactive tracks performance</h3>\n","    <p> Run the following cell to execute the test case for the performance of the inactive tracker. The second row serves as a reference.</p>\n","</div>"]},{"cell_type":"code","source":["!pip install lap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gZl0qbJmO52","executionInfo":{"status":"ok","timestamp":1702743269678,"user_tz":-60,"elapsed":19538,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"7289c1b7-771c-44cb-bd85-869f26cba21b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lap\n","  Downloading lap-0.4.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: lap\n","  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lap: filename=lap-0.4.0-cp310-cp310-linux_x86_64.whl size=1628964 sha256=c034686bdeadef6b520ec699001456dfb9ababe296d6f40eeef4a8b313d88b38\n","  Stored in directory: /root/.cache/pip/wheels/00/42/2e/9dfe19270eea279d79e84767ff0d7b8082c3bf776cad00e83d\n","Successfully built lap\n","Installing collected packages: lap\n","Successfully installed lap-0.4.0\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DsI0BW2Jbn1M","executionInfo":{"status":"ok","timestamp":1702743280564,"user_tz":-60,"elapsed":10903,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"c2984896-3dc2-41d3-c55c-193865df0d65"},"outputs":[{"output_type":"stream","name":"stdout","text":["              IDF1       IDP       IDR      Rcll      Prcn  GT  MT  PT  ML   FP    FN  IDs   FM      MOTA      MOTP   IDt    IDa  IDm\n","MOT16-02  0.457617  0.649832  0.353156  0.522469  0.961378  62  12  37  13  390  8873  133  210  0.494322  0.090339  17.0  119.0  5.0\n","MOT16-02  0.457617  0.649832  0.353156  0.522469  0.961378  62  12  37  13  390  8873  133  210  0.494322  0.090339   NaN    NaN  NaN\n","Congratulations: Longterm_Hungarian_TrackerIoUReID seems to be correct for sequence MOT16-02 based on the metrics: mota idf1.\n","              IDF1       IDP       IDR      Rcll      Prcn   GT  MT  PT  ML   FP    FN  IDs   FM      MOTA      MOTP   IDt    IDa   IDm\n","MOT16-05  0.583493  0.690091  0.505421  0.688304  0.939795  133  54  67  12  305  2156  289  149  0.602429  0.141942  71.0  226.0  13.0\n","MOT16-05  0.583493  0.690091  0.505421  0.688304  0.939795  133  54  67  12  305  2156  289  149  0.602429  0.141942   NaN    NaN   NaN\n","Congratulations: Longterm_Hungarian_TrackerIoUReID seems to be correct for sequence MOT16-05 based on the metrics: mota idf1.\n","              IDF1       IDP       IDR      Rcll     Prcn  GT  MT  PT  ML  FP    FN  IDs  FM     MOTA      MOTP   IDt   IDa  IDm\n","MOT16-09  0.508558  0.628943  0.426854  0.663286  0.97731  26  13  12   1  82  1793   51  76  0.63831  0.082643  12.0  42.0  4.0\n","MOT16-09  0.508558  0.628943  0.426854  0.663286  0.97731  26  13  12   1  82  1793   51  76  0.63831  0.082643   NaN   NaN  NaN\n","Congratulations: Longterm_Hungarian_TrackerIoUReID seems to be correct for sequence MOT16-09 based on the metrics: mota idf1.\n","              IDF1      IDP       IDR      Rcll      Prcn  GT  MT  PT  ML   FP    FN  IDs  FM      MOTA      MOTP   IDt    IDa  IDm\n","MOT16-11  0.650489  0.71715  0.595167  0.801717  0.966032  75  44  24   7  266  1871  143  91  0.758372  0.082736  24.0  121.0  3.0\n","MOT16-11  0.650489  0.71715  0.595167  0.801717  0.966032  75  44  24   7  266  1871  143  91  0.758372  0.082736   NaN    NaN  NaN\n","Congratulations: Longterm_Hungarian_TrackerIoUReID seems to be correct for sequence MOT16-11 based on the metrics: mota idf1.\n","Method () correctly implemented. Tests passed: 4/4\n","              MOTA\n","MOT16-02  0.494322\n","MOT16-05  0.602429\n","MOT16-09  0.638310\n","MOT16-11  0.758372\n","Your tracker Longterm_Hungarian_TrackerIoUReID reached the mean mota 0.62 on sequence MOT16-reid.\n","Test passed 62/100\n","Score: 81/100\n"]}],"source":["_ = test_longterm_hungarian_tracking_ioureid()"]},{"cell_type":"markdown","metadata":{"id":"qHNACiPybn1M"},"source":["## Part II - Building a tracker based on Neural Message Passing\n","\n","Our ``Longterm_Hungarian_TrackerIoUReID`` is still limited when compared to current modern trackers. One disadvantage is that our tracker can only account for pairwise similarities among objects. Ideally, we would like it also to consider higher-order information.\n","\n","To address this limitation, we will now build a tracker combining appearance and position information with a Message Passing Neural Network, inspired by the approach presented in [0].\n","\n","The idea is to build a bipartite graph containing two sets of nodes for every tracking step: past tracks $A$ and detections $B$ in the current frame, and our set of edges will be $A\\times B$. That is, we will connect every past track with every detection.\n","We will have initial node features (i.e. reid embeddings) matrices: $X_A \\in \\R^{|A| \\times \\text{node\\_dim}}$ and $X_B \\in \\R^{|B|\\times \\text{node\\_dim}}$ and an initial edge features tensor $E\\in \\R^{|A| \\times |B| \\times \\text{edge\\_dim}}$.\n","That means its $(i, j)$-th entry contains the edge features between node $i$ in $A$ and node $j$ in $B$.\n","\n","We will use an MPN to refine these edge embeddings. For this, we will first build a Neural Message Passing layer based on the Graph Networks framework introduced in [1], as explained in the *A More General Framework* slides of [Lecture 5](https://youtu.be/BR3Y5bAz5Dw) (slides 70 to 75) of the old lecture recordings.\n","\n","With the given layer, we will produce new node feature matrices $X_A'$ and $X_B'$ and edge features $E'$ with the same dimensionality.\n","The learning task will be to classify the edge embeddings in this graph, which is equivalent to predicting the entries of our data association similarity matrix.\n","\n","[0] [Learning a Neural Solver for Multiple Object Tracking](https://arxiv.org/abs/1912.07515)\n","\n","[1] [Relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261)\n","\n","[2] [Brasó and Leal-Taixé, Learning a Neural Solver for Multiple Object Tracking, CVPR 2020](https://arxiv.org/abs/1912.07515)\n","\n","[3] [Battaglia et al., Relational inductive biases, deep learning, and graph networks, arXiv 2018](https://arxiv.org/abs/1806.01261)\n"]},{"cell_type":"markdown","metadata":{"id":"1ZTYWaSnbn1M"},"source":["\n","<div class=\"alert alert-info\">\n","    <h3>Task: Neural Message Passing I</h3>\n","    <p> You have to implement a part of the neural message passing layer by adding the node and edge update steps. Go to <code>exercise_code/model/assign_net.py</code> and the class <code>BipartiteNeuralMessagePassingLayer</code>. There you need to complete the methods <code>edge_update(self, edge_embeds, nodes_a_embeds, nodes_b_embeds)</code> and <code>node_update(self, edge_embeds, nodes_a_embeds, nodes_b_embeds)</code>.\n","    <br>\n","    Note: You do not need to care about batching several graphs. This implementation will only work with a single graph at a time.\n","    </p>\n","</div>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"0-pH3mP_bn1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702743287113,"user_tz":-60,"elapsed":6107,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"c499f61b-b8be-46f1-e724-e88f99e6e334"},"outputs":[{"output_type":"stream","name":"stdout","text":["Congratulations: The shape of the Edge Update seems to be correct\n","Congratulations: The shape of the Node Update seems to be correct\n","Congratulations: The input to the node MLP seems to be correct\n","Congratulations: The input to the edge MLP seems to be correct\n","All tests of NeuralMessagePassing passed. Tests passed: 4/4\n","Score: 100/100\n"]}],"source":["_ = test_neural_message_passing_1()"]},{"cell_type":"markdown","metadata":{"id":"wnrLJT0Ebn1N"},"source":["## Building the entire network to predict similarities\n","We now build the network that generates initial node and edge features, performs neural message passing, and classifies edges in order to produce the final costs that we will use for data association.\n","\n","[2] proposes, given two bounding boxes $(x_i, y_i, w_i, h_i)$ and  $(x_j, y_j, w_j, h_j)$ and timestamps $t_i$ and $t_j$, to compute an initial 5-dimensional edge feature vector as:\n","$$ E_{(i, j)} = \\left(\\frac{2(x_j - x_i)}{h_i + h_j}, \\frac{2(y_j - y_i)}{h_i + h_j}, \\log{\\frac{h_i}{h_j}}, \\log{\\frac{w_i}{w_j}}, t_j - t_i \\right )$$"]},{"cell_type":"markdown","metadata":{"id":"jAhjY_TXbn1N"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Neural Message Passing II</h3>\n","    <p> Go to <code>exercise_code/model/message_passing_network.py</code> and the class <code>AssignmentSimilarityNet</code>. There you need to complete the methods <code>compute_motion_edge_feats(self, track_coords, current_coords, track_t, curr_t)</code> method. Previously, we used the IoU between predictions and detections as motion prior. Now, you can use the edge feature proposed in [1] as detailed in the cell above.\n","    <br>\n","    Feel free to engineer your own features (e.g. use IoU, etc.)</p>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"dgEx7L5Qbn1O"},"source":["<div class=\"alert alert-danger\">\n","    <h3>Test: Neural Message Passing</h3>\n","    <p> Run the following cell to execute the test case for the second task of regarding neural message passing. This test will check the correct implementation of the given feature vector. If you implemented your own feature vector, this test will likely fail. However, you can adjust the feature dimension accordingly to pass the shape test. </p>\n","</div>"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQJgaytqbn1O","executionInfo":{"status":"ok","timestamp":1702743287113,"user_tz":-60,"elapsed":14,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"4aedc171-7aa8-4890-d65e-6e4cb127bfa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Congratulations: The shape of the Edge Initialization seems to be correct\n","All tests of NeuralMessagePassing passed. Tests passed: 1/1\n","Score: 100/100\n"]}],"source":["_ = test_neural_message_passing_2()"]},{"cell_type":"markdown","metadata":{"id":"sGgEwWjObn1P"},"source":["## Putting everything together\n","Finally, we test our ``AssignmentSimilarityNet``, which will output a refined similarity matrix, which we can use for linear assignment. The forward pass through the assignment net will initialize the edge and node features and run the specified number of update iterations. The output is then a tensor of similarity matrices whose first dimension is the number of update steps."]},{"cell_type":"markdown","metadata":{"id":"SAXbUZaGbn1P"},"source":["\n","Finally, we can integrate the AssignmentNet into our Tracker. We can keep everything as in ``LongTermReIDHungarianTracker`` except for the distance computation, which is now directly obtained via a forward pass through AssignmentSimilarityNet."]},{"cell_type":"markdown","metadata":{"id":"df2iJjWkbn1P"},"source":["<div class=\"alert alert-info\">\n","    <h3>Task: Doing a Forward Pass</h3>\n","    <p> Go to <code>exercise_code/model/message_passing_network.py</code> and the class <code>MPN_Tracker</code>. There you need perform a forward pass through the <code>AssignmenSimilarityNet</code>.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"C09c0LSZbn1P"},"source":["<div class=\"alert alert-danger\">\n","    <h3>Test: Doing a Forward Pass</h3>\n","    <p> Run the following cell to execute the test case for running a forward pass.</p>\n","</div>"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3hX-OcZQbn1Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702743287114,"user_tz":-60,"elapsed":12,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"99a05d68-20a5-4460-efb3-0b617b03edef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Congratulations: The forward pass seems to work\n","All tests of ForwardPassTest passed. Tests passed: 1/1\n","Score: 100/100\n"]}],"source":["_ = test_mpn_tracking_forward_pass()"]},{"cell_type":"markdown","metadata":{"id":"Pf2COETNbn1Q"},"source":["## Training and evaluating our model\n","\n","We provide all boilerplate code for training and evaluating our neural message passing tracker. Under the hood, we randomly sample boxes of frames from our training sequences to generate $A$. Then, we add sampled boxes from past frames to generate our second set $B$. Check out `LongTrackTrainingDataset` for details.\n","\n","We train the model with a weighted cross-entropy loss to account for the class imbalance and add a weight $w>1$ for the positive samples in the binary cross-entropy loss. Check out `exercise_code/model/trainer.py`.\n","$$\n","\\sum_{{i,j}} w \\cdot y_{i,j} \\log\\left(\\hat{y}_{i,j} \\right) + \\left(1-y_{i,j}\\right)\\log\\left(1- \\hat{y}_{i,j}\\right),\n","$$ where $$y_{i,j} \\in\\{ 0,1\\}$$ is one, if the edge is a match in the training data and zero, otherwise. The variable $$\\hat{y_{i,j}} \\in[0,1]$$ denotes the learned output probability of the edge being active, which we use for classification. No need to write any code from your side here!\n","\n","Expert Knowledge: The binary cross entropy loss is minimizing the likelihood of statistically independent Bernoulli Experiments with success probability $\\hat{y}_{i,j}\\in[0,1]$\n","$$\n","\\operatorname{arg}\\min \\prod_{i,j} \\hat{y}_{i,j}^{y_{i,j}} +  (1-\\hat{y}_{i,j})^{(1-{y_{i,j}})}.\n","$$\n","How is the weighted cross-entropy loss related to unbalanced data?\n","It penalizes more positive labels that are falsely classified, hence helping increase recall; you can expect your ML model to become more sensitive in correctly classifying positive cases out of all actual positives.\n","(Note: Recall=TP/P=TP/(TP+FN))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ihoCDEUwbn1Q","executionInfo":{"status":"ok","timestamp":1702743287114,"user_tz":-60,"elapsed":10,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}}},"outputs":[],"source":["# Define our model, and init\n","assign_net = AssignmentSimilarityNet(reid_network=None, # Not needed since we work with precomputed features\n","                                     node_dim=32,\n","                                     edge_dim=64,\n","                                     reid_dim=512,\n","                                     edges_in_dim=6,\n","                                     num_steps=10).to(device)"]},{"cell_type":"markdown","metadata":{"id":"INExquoSbn1Q"},"source":["We only leave two sequences for validation in order to maximize the amount of training data."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"8s9xT6bmbn1Q","executionInfo":{"status":"ok","timestamp":1702743298652,"user_tz":-60,"elapsed":11548,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}}},"outputs":[],"source":["MAX_PATIENCE = 20\n","train_db = torch.load(dataset_dir.joinpath('reid_gnn', 'preprocessed_data_train_2.pth'))\n","# We only keep two sequences for validation\n","dataset = LongTrackTrainingDataset(dataset='MOT16-train_wo_val',\n","                                   db=train_db,\n","                                   root_dir=dataset_dir.joinpath('MOT16'),\n","                                   max_past_frames=MAX_PATIENCE,\n","                                   vis_threshold=0.25)\n","data_loader = DataLoader(dataset,\n","                        batch_size=8,\n","                        collate_fn=lambda x: x,\n","                        shuffle=True,\n","                        num_workers=2,\n","                        drop_last=True)\n","dataset_val = LongTrackTrainingDataset(dataset='MOT16-val',\n","                                   db=train_db,\n","                                   root_dir=dataset_dir.joinpath('MOT16'),\n","                                   max_past_frames=MAX_PATIENCE,\n","                                   vis_threshold=0.25)\n","data_loader_val = DataLoader(dataset_val,\n","                        batch_size=8,\n","                        collate_fn=lambda x: x,\n","                        shuffle=True,\n","                        num_workers=2,\n","                        drop_last=True)\n","val_sequences = MOT16Sequences('MOT16-val',\n","                        dataset_dir.joinpath('MOT16'),\n","                        vis_threshold=0.25)"]},{"cell_type":"markdown","metadata":{"id":"G0zt8J3hbn1R"},"source":["### Let's start training!\n","\n","Note that we have observed quite a lot of noise in validation scores among epochs and runs. That is due to the small size of our training and validation sets. Therefore, we perform early stopping to obtain the best-performing model on validation. In addition, changing the experiment seed and/ or relaunching the training might help if you suspect noise influencing your scores."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"1Pc9Bs5Fbn1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702743440315,"user_tz":-60,"elapsed":141699,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"2f6d15f5-1049-45ba-842d-90511e87dc43"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------- EPOCH  1 --------\n","cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["100it [00:33,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["Iter 100. Loss: 5.274. Accuracy: 0.925. Recall: 0.610. Precision: 0.321\n"]},{"output_type":"stream","name":"stderr","text":["200it [01:05,  3.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Iter 200. Loss: 4.594. Accuracy: 0.993. Recall: 0.987. Precision: 0.880\n"]},{"output_type":"stream","name":"stderr","text":["278it [01:29,  3.12it/s]"]},{"output_type":"stream","name":"stdout","text":["-------- Validation --------\n"]},{"output_type":"stream","name":"stderr","text":["\n","187it [00:36,  5.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Iter 187. Loss: 868.159. Accuracy: 0.997. Recall: 0.995. Precision: 0.960\n","Runtime for all sequences: 13.3 s.\n","              IDF1\n","MOT16-02  0.419331\n","MOT16-11  0.669369\n","Your tracker MPN_Tracker reached the mean idf1 0.54 on sequence MOT16-val.\n","Test passed 54/100\n"]}],"source":["# Init the optimizer and lr scheduler\n","optimizer = torch.optim.Adam(assign_net.parameters(), lr=0.001)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5)\n","MAX_EPOCHS = 1 # adjust this for longer training, if you have problems with your GPU, try to train only for one epoch and continue with the rest of the exercise\n","EVAL_FREQ = 1\n","\n","score_best = 0\n","for epoch in range(1, MAX_EPOCHS + 1):\n","    print(f\"-------- EPOCH {epoch:2d} --------\")\n","    train_assign_net_one_epoch(model=assign_net, data_loader=data_loader, optimizer=optimizer, print_freq=100)\n","    scheduler.step()\n","\n","    if epoch % EVAL_FREQ == 0:\n","        print(f\"-------- Validation --------\")\n","        # validation on long tracking dataset\n","        metrics_accum = evaluate_assign_net(model=assign_net.eval(), data_loader=data_loader_val)\n","        # validation using the tracker\n","        tracker = MPN_Tracker(assign_net=assign_net.eval(), patience=MAX_PATIENCE)\n","        results_seq = run_tracker(val_sequences, db=train_db, tracker=tracker, device=device)\n","        torch.save(results_seq, \"exercise_code/test/\"+tracker.name+\".pth\")\n","        score = val_mpn_tracking()\n","        if score>score_best:\n","            score_best=score\n","            torch.save(assign_net, output_dir.joinpath(\"assign_net.pth\"))\n","        # if score > score_best:\n","        #     score_best = score\n","        #     # Save the state dictionary of the model instead of the entire object\n","        #     torch.save(assign_net.state_dict(), output_dir.joinpath(\"assign_net.pth\"))\n","        #     # torch.save(assign_net.state_dict(), \"/content/gdrive/MyDrive/masters/CVIII/task3/exercise_03/models/assign_net.pth\")\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Ipuds9-bbn1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702743454091,"user_tz":-60,"elapsed":13803,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"cfa591eb-65c9-497b-a536-3c344ea45be1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Runtime for all sequences: 13.6 s.\n"]}],"source":["assign_net = torch.load( output_dir.joinpath(\"assign_net.pth\"))\n","\n","# Load the saved state dictionary\n","# state_dict = torch.load(output_dir.joinpath(\"assign_net.pth\"))\n","# assign_net.load_state_dict(state_dict)\n","\n","tracker =  MPN_Tracker(assign_net=assign_net.eval(), patience=MAX_PATIENCE)\n","val_sequences = MOT16Sequences('MOT16-val',\n","                        dataset_dir.joinpath('MOT16'),\n","                        vis_threshold=0.25)\n","results_seq = run_tracker(val_sequences, train_db, tracker, device=device)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wMDxTIe7bn1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702743459041,"user_tz":-60,"elapsed":4978,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"1a2159aa-0ed3-453e-b126-8a889200b5e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["              IDF1       IDP       IDR      Rcll      Prcn  GT  MT  PT  ML   FP    FN  IDs   FM      MOTA      MOTP   IDt    IDa  IDm\n","MOT16-02  0.419331  0.595464  0.323610  0.522469  0.961378  62  11  38  13  390  8873  177  221  0.491954  0.094603  51.0  114.0  3.0\n","MOT16-02  0.457617  0.649832  0.353156  0.522469  0.961378  62  12  37  13  390  8873  133  210  0.494322  0.090339   NaN    NaN  NaN\n","Congratulations: MPN_Tracker seems to be correct for sequence MOT16-02 based on the metrics: mota idf1.\n","              IDF1       IDP       IDR      Rcll      Prcn  GT  MT  PT  ML   FP    FN  IDs  FM      MOTA      MOTP   IDt   IDa  IDm\n","MOT16-11  0.669369  0.737965  0.612442  0.801717  0.966032  75  44  24   7  266  1871  169  96  0.755617  0.082536  11.0  37.0  1.0\n","MOT16-11  0.650489  0.717150  0.595167  0.801717  0.966032  75  44  24   7  266  1871  143  91  0.758372  0.082736   NaN   NaN  NaN\n","Congratulations: MPN_Tracker seems to be correct for sequence MOT16-11 based on the metrics: mota idf1.\n","Method () correctly implemented. Tests passed: 2/2\n","              MOTA\n","MOT16-02  0.491954\n","MOT16-11  0.755617\n","Your tracker MPN_Tracker reached the mean mota 0.62 on sequence MOT16-val.\n","Test passed 62/100\n","Score: 81/100\n"]}],"source":["torch.save(results_seq, \"exercise_code/test/\"+tracker.name+\".pth\")\n","_ = test_mpn_tracking()"]},{"cell_type":"markdown","metadata":{"id":"hjPRHopFbn1S"},"source":["# Exercise submission"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADKAV5EZbn1S","executionInfo":{"status":"ok","timestamp":1702743600830,"user_tz":-60,"elapsed":25284,"user":{"displayName":"Mohamed Ayman","userId":"02973357479498399481"}},"outputId":"18d63470-d212-4437-fe19-1328536df461"},"outputs":[{"output_type":"stream","name":"stdout","text":["relevant folders: ['exercise_code', 'models']\n","notebooks files: ['reid_gnn.ipynb']\n","Adding folder exercise_code\n","Adding folder models\n","Adding notebook reid_gnn.ipynb\n","Zipping successful! Zip is stored under: /content/gdrive/.shortcut-targets-by-id/1m6r3Eg6UCvByUZTaC9M5ScZDSuzPe97Q/masters/CVIII/output/exercise03.zip\n"]}],"source":["from exercise_code.submit import submit_exercise\n","\n","submit_exercise('../output/exercise03')"]},{"cell_type":"code","source":[],"metadata":{"id":"Qljhn2NPuEnZ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"b38045e10271186d31b9c7cfcf32f44b81f9b46f72bad763493647421023d2a5"}},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}